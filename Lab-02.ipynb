{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Algebra for Neural Networks\n",
    "Linear algebra plays a crucial role in understanding and implementing neural networks. Here are some key concepts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Vectors\n",
    "\n",
    "> In neural networks, vectors are often used to represent inputs, weights, biases, and outputs of individual neurons or layers. Vector operations, such as addition, subtraction, and scalar multiplication, are fundamental operations in linear algebra and are commonly used in neural network computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Addition & Subtraction\n",
    "\n",
    "These operations play a crucial role in various aspects of neural network computations, such as forward propagation, backpropagation, and weight updates. They enable the network to learn and adapt to different patterns and relationships in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### *1.2.1. Addition*\n",
    "\n",
    "\tVector addition is used to combine the inputs from multiple neurons or layers. It allows us to aggregate information and create more complex representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two vectors\n",
    "vector1 = [1, 2, 3]\n",
    "vector2 = [4, 5, 6]\n",
    "\n",
    "# Perform vector addition\n",
    "result = [x + y for x, y in zip(vector1, vector2)]\n",
    "\n",
    "print(\"Result:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same example using NumPy\n",
    "import numpy as np\n",
    "\n",
    "# Define two vectors\n",
    "vector1 = np.array([1, 2, 3])\n",
    "vector2 = np.array([4, 5, 6])\n",
    "\n",
    "# Perform vector addition\n",
    "result = np.add(vector1, vector2)\n",
    "\n",
    "print(\"Result:\", result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### *1.2.2. Subtraction*\n",
    "\n",
    "\tVector subtraction is used to calculate the difference between two vectors. It can be used to measure the distance or dissimilarity between two sets of features or to perform element-wise comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two vectors\n",
    "vector1 = [1, 2, 3]\n",
    "vector2 = [4, 5, 6]\n",
    "\n",
    "# Perform vector subtraction\n",
    "result = [x - y for x, y in zip(vector1, vector2)]\n",
    "\n",
    "print(\"Result:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same example using NumPy\n",
    "import numpy as np\n",
    "\n",
    "# Define two vectors\n",
    "vector1 = np.array([1, 2, 3])\n",
    "vector2 = np.array([4, 5, 6])\n",
    "\n",
    "# Perform vector subtraction\n",
    "result = np.subtract(vector1, vector2)\n",
    "\n",
    "print(\"Result:\", result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Vector Dot Product\n",
    "\n",
    "The dot product is used to calculate the similarity between two vectors. In neural networks, it is often used to calculate the weighted sum of inputs and weights.\n",
    "\n",
    "\t* Note that np.dot performs dot product only on vectors, otherwise it performs matrix multiplication underneath the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define two vectors\n",
    "vector1 = np.array([1, 2, 3])\n",
    "vector2 = np.array([4, 5, 6])\n",
    "\n",
    "# Perform dot product\n",
    "dot_product = np.dot(vector1, vector2)\n",
    "\n",
    "print(\"Dot Product:\", dot_product)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Matrices\n",
    "\n",
    "> Matrices are used to represent the connections between layers in a neural network. Each element in the matrix represents the weight of the connection between two neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a matrix\n",
    "matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "print(matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Subtraction and Addition\n",
    "Pretty much the same as Vector subtraction and addition, you add or subtract the corresponding element as long as both matrices has the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define two matrices\n",
    "matrix1 = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "matrix2 = np.array([[7, 8, 9], [10, 11, 12]])\n",
    "\n",
    "# Perform matrix subtraction\n",
    "subtraction_result = np.subtract(matrix1, matrix2)\n",
    "\n",
    "# Perform matrix addition\n",
    "addition_result = np.add(matrix1, matrix2)\n",
    "\n",
    "print(\"Subtraction Result:\")\n",
    "print(subtraction_result)\n",
    "\n",
    "print(\"Addition Result:\")\n",
    "print(addition_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Matrix Multiplication\n",
    "\n",
    "Matrix multiplication is used to propagate inputs through the layers of a neural network. It involves multiplying the input vector with the weight matrix to produce the output matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define two matrices\n",
    "matrix1 = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "matrix2 = np.array([[7, 8], [9, 10], [11, 12]])\n",
    "\n",
    "# Perform matrix multiplication\n",
    "result = np.matmul(matrix1, matrix2)\n",
    "\n",
    "# Another way to perform matrix multiplication\n",
    "result = matrix1 @ matrix2\n",
    "\n",
    "# Another way to perform matrix multiplication\n",
    "result = np.dot(matrix1, matrix2) # the np.dot here DOES NOT PERFORM DOT PRODUCT, it performs matrix multiplication\n",
    "\n",
    "print(\"Result:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Vector Dot Product vs Matrix Multiplication\n",
    "\n",
    "> Both dot product and matrix multiplication are mathematical operations used in linear algebra and have different purposes and applications. Understanding the difference between them is crucial for effectively using them in various scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Vector Dot Product\n",
    "\n",
    "The dot product, also known as the scalar product or inner product, is an operation between two vectors that results in a scalar value. It calculates the similarity or projection of one vector onto another. The dot product is calculated by multiplying the corresponding elements of the vectors and summing them up.\n",
    "\n",
    "The dot product is useful in various applications, including:\n",
    "\n",
    "- `Calculating the similarity between two vectors`: The dot product can be used to measure the similarity or correlation between two vectors. If the dot product is close to zero, the vectors are orthogonal or independent. If the dot product is positive, the vectors are pointing in a similar direction, and if it is negative, they are pointing in opposite directions.\n",
    "\n",
    "- `Calculating the projection of a vector onto another`: The dot product can be used to calculate the projection of one vector onto another. The projection represents the component of one vector that lies in the direction of the other vector.\n",
    "\n",
    "- `Calculating the magnitude of a vector`: The dot product of a vector with itself gives the square of its magnitude or length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Matrix Multiplication\n",
    "\n",
    "Matrix multiplication is an operation between two matrices that results in a new matrix. It involves multiplying the corresponding elements of the matrices and summing them up. The resulting matrix has dimensions determined by the dimensions of the input matrices.\n",
    "\n",
    "Matrix multiplication is useful in various applications, including:\n",
    "\n",
    "- `Transforming vectors and coordinates`: Matrix multiplication can be used to transform vectors and coordinates in different coordinate systems. It is commonly used in computer graphics, computer vision, and robotics to perform transformations such as translation, rotation, scaling, and shearing.\n",
    "\n",
    "- `Propagating inputs through neural networks`: In neural networks, matrix multiplication is used to propagate inputs through the layers. Each layer in a neural network can be represented as a matrix, and matrix multiplication is used to calculate the outputs of each layer based on the inputs and weights.\n",
    "\n",
    "- `Solving systems of linear equations`: Matrix multiplication can be used to solve systems of linear equations. By representing the system of equations as a matrix equation, matrix multiplication can be used to find the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. When to Use Dot Product and Matrix Multiplication\n",
    "\n",
    "- Use `dot product` when you need to measure similarity, calculate projections, or find the magnitude of vectors.\n",
    "\n",
    "- Use `matrix multiplication` when you need to transform vectors and coordinates, propagate inputs through neural networks, or solve systems of linear equations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. When Not to Use Dot Product and Matrix Multiplication\n",
    "\n",
    "- `Dot product` cannot be used when the dimensions of the vectors are not compatible. The dot product is only defined for vectors of the same length.\n",
    "\n",
    "- `Matrix multiplication` cannot be used when the dimensions of the matrices are not compatible. The number of columns in the first matrix must be equal to the number of rows in the second matrix.\n",
    "\n",
    "- `Dot product and matrix multiplication` may not be suitable for non-linear operations or when dealing with non-linear data. In such cases, other mathematical operations or algorithms may be more appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. In Conclusion\n",
    "\n",
    "Dot Product and Matrix Multiplication are different operations between different objects.\n",
    "\n",
    "\t* Dot product is defined between two vectors.\n",
    "\n",
    "\t* Matrix product is defined between two matrices.\n",
    "\n",
    "The connection between the two operations is the following: To calculate the c<sub>i,j</sub> entry of the matrix C:=AB, one takes the dot product of the `i'th row of the matrix A` with the `j'th column of the matrix B`.\n",
    "\n",
    "Understanding the differences between dot product and matrix multiplication and knowing when to use them is essential for effectively applying linear algebra concepts in various fields, including machine learning, computer science, and engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the input vector\n",
    "input_vector = np.array([1, 2, 3])\n",
    "\n",
    "# Define the weight matrix (Imagine these are the weights which are learned during training)\n",
    "weight_matrix = np.array([[0.1, 0.2, 0.3],\n",
    "                          [0.4, 0.5, 0.6],\n",
    "                          [0.7, 0.8, 0.9]])\n",
    "\n",
    "# Define the bias vector\n",
    "bias_vector = np.array([0.1, 0.2, 0.3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the weighted sum using np.dot\n",
    "weighted_sum = np.dot(input_vector, weight_matrix) + bias_vector # the np.dot here DOES NOT PERFORM DOT PRODUCT, it performs matrix multiplication\n",
    "activation = 1 / (1 + np.exp(-weighted_sum))\n",
    "\n",
    "print(\"Weighted Sum:\", weighted_sum)\n",
    "print(\"Activation:\", activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the weighted sum using matrix multiplication\n",
    "weighted_sum = np.matmul(input_vector, weight_matrix) + bias_vector\n",
    "activation = 1 / (1 + np.exp(-weighted_sum))\n",
    "\n",
    "print(\"Weighted Sum:\", weighted_sum)\n",
    "print(\"Activation:\", activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Tensors\n",
    "\n",
    "> Tensors are multi-dimensional arrays that generalize scalars, vectors, and matrices. They are used to represent and manipulate data in various fields, including mathematics, physics, and computer science Tensors enable efficient computation, parallel processing, and automatic differentiation, making them essential for working with neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Mathematical Concept of Tensors\n",
    "\n",
    "In mathematics, tensors are multi-dimensional arrays that generalize the concepts of scalars, vectors, and matrices. They are used to represent and manipulate data in various fields, including physics, engineering, and computer science.\n",
    "\n",
    "## 4.1.1. Rank and Shape of Tensors\n",
    "\n",
    "Tensors have two important properties: rank and shape.\n",
    "\n",
    "- `Rank`: The rank of a tensor refers to the number of dimensions it has. For example, a scalar has rank 0, a vector has rank 1, a matrix has rank 2, and so on.\n",
    "\n",
    "- `Shape`: The shape of a tensor describes the size of each dimension. For example, a 2D tensor with shape (3, 4) has 3 rows and 4 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.2. Tensor Operations\n",
    "\n",
    "Tensors support various mathematical operations, such as addition, subtraction, multiplication, and division. These operations can be performed element-wise or using matrix operations, depending on the rank and shape of the tensors involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Create tensors\n",
    "tensor1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "tensor2 = torch.tensor([[7, 8, 9], [10, 11, 12]])\n",
    "\n",
    "# Perform tensor addition\n",
    "addition_result = torch.add(tensor1, tensor2)\n",
    "\n",
    "# Perform tensor subtraction\n",
    "subtraction_result = torch.sub(tensor1, tensor2)\n",
    "\n",
    "# Perform tensor multiplication\n",
    "multiplication_result = torch.mul(tensor1, tensor2)\n",
    "\n",
    "# Perform tensor division\n",
    "division_result = torch.div(tensor1, tensor2)\n",
    "\n",
    "print(\"Addition Result:\")\n",
    "print(addition_result)\n",
    "\n",
    "print(\"Subtraction Result:\")\n",
    "print(subtraction_result)\n",
    "\n",
    "print(\"Multiplication Result:\")\n",
    "print(multiplication_result)\n",
    "\n",
    "print(\"Division Result:\")\n",
    "print(division_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.3. Tensor Types\n",
    "\n",
    "There are different types of tensors, including:\n",
    "\n",
    "- `Scalar`: A scalar is a tensor of rank 0, representing a single value.\n",
    "\n",
    "- `Vector*`: A vector is a tensor of rank 1, representing a list of values arranged in a specific order.\n",
    "\n",
    "- `Matrix*`*`: A matrix is a tensor of rank 2, representing a 2D array of values.\n",
    "\n",
    "- `Higher-Rank Tensors`: Tensors of rank 3 or higher are called higher-rank tensors. They represent multi-dimensional arrays of values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Importance of Tensors in Neural Networks\n",
    "\n",
    "Tensors play a crucial role in neural networks for several reasons:\n",
    "\n",
    "1. **Data Representation**: Tensors provide a flexible and efficient way to represent and store data. They can handle complex data structures, such as images, audio, and text, which are commonly used in machine learning tasks.\n",
    "\n",
    "2. **Computation**: Tensors enable efficient computation in neural networks. They support various mathematical operations, such as element-wise operations, matrix multiplication, and convolution, which are essential for performing forward and backward propagation in neural networks.\n",
    "\n",
    "3. **Parallel Processing**: Tensors can be easily parallelized and processed on specialized hardware, such as GPUs (Graphics Processing Units) and TPUs (Tensor Processing Units). This allows for faster training and inference in neural networks, especially for large-scale models and datasets.\n",
    "\n",
    "4. **Automatic Differentiation**: Tensors are used to store intermediate values during the forward and backward passes in neural networks. They enable automatic differentiation, which is essential for calculating gradients and updating the model parameters during the training process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Weighted sum example with tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Define the input vector\n",
    "input_vector = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Define the weight matrix (Imagine these are the weights which are learned during training)\n",
    "weight_matrix = torch.tensor([[0.1, 0.2, 0.3],\n",
    "                              [0.4, 0.5, 0.6],\n",
    "                              [0.7, 0.8, 0.9]])\n",
    "\n",
    "# Define the bias vector\n",
    "bias_vector = torch.tensor([0.1, 0.2, 0.3])\n",
    "\n",
    "# calculate the weighted sum using torch.matmul\n",
    "weighted_sum = torch.matmul(input_vector, weight_matrix) + bias_vector\n",
    "activation = 1 / (1 + torch.exp(-weighted_sum))\n",
    "\n",
    "print(\"Weighted Sum:\", weighted_sum)\n",
    "print(\"Activation:\", activation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Conclusion\n",
    "\n",
    "The mathematical concept of tensors provides a powerful framework for representing and manipulating multi-dimensional data. Understanding tensors is crucial for various fields, including mathematics, physics, and machine learning. By leveraging tensors, we can solve complex problems and build sophisticated models that can handle large-scale data efficiently.\n",
    "\n",
    "Tensors are a fundamental concept in neural networks. They provide a powerful and efficient way to represent and process numerical data, enabling the development and training of complex models. Understanding tensors is crucial for effectively working with neural networks and achieving optimal performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Understanding these linear algebra concepts is essential for building and training neural networks effectively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
