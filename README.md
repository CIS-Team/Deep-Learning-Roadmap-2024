# Hands-On Labs for Neural Networks with PyTorch

This repository contains a series of hands-on labs for beginners in neural networks using PyTorch. The labs are designed to briefly cover various topics, including Maths basics, Python refresher, and neural network concepts.

## Topics Covered

### 1. Maths Basics
- Linear Algebra: Introduction to linear algebra concepts used in neural networks.
- Calculus: Exploring calculus concepts relevant to neural networks.

### 2. Python Refresher & Environment Setup
- Miniconda Installation and Environment Setup: Step-by-step guide for installing Miniconda and setting up the environment.
- Python Refresher: Implementation of Maths functions.
- PyTorch: Getting started with PyTorch library for neural networks development.

### 3. Neural Network Concepts
- Neurons and Activation Functions: Understanding the building blocks of neural networks.
- Forward and Back Propagation: Implementing forward and back propagation algorithms in neural networks.
- Dense Neural Networks: Building and training dense neural networks.
- Convolutional Neural Networks (CNN): Introduction to CNNs and their applications in computer vision tasks.
- Recurrent Neural Networks (RNN): Exploring RNNs and their ability to process sequential data.
- Long Short-Term Memory (LSTM): Understanding LSTM networks and their role in handling long-term dependencies.
- Transfer Learning: Leveraging pre-trained models for transfer learning in neural networks.

## Labs

### 1. Introduction to Neural Networks
- Overview of neural networks, their applications, and workflow.

### 2. Linear Algebra for Neural Networks
- Understanding linear algebra concepts used in neural networks.

### 3. Calculus for Neural Networks
- Exploring calculus concepts relevant to neural networks.

### 4. Miniconda Installation and Environment Setup
- Step-by-step guide for installing Miniconda and setting up the environment with needed libraries.

### 5. Python Refresher & PyTorch
- Implementing maths concepts as a Python refresher and getting started with Pytorch for neural network development.

### 6. Neurons and Activation Functions
- Understanding the building blocks of neural networks: neurons and activation functions.

### 7. Forward and Back Propagation
- Implementing forward and back propagation algorithms in neural networks.

### 8. Dense Neural Networks
- Building and training dense neural networks.

### 9. Convolutional Neural Networks (CNN)
- Introduction to CNNs and their applications in computer vision tasks.

### 10. Recurrent Neural Networks (RNN)
- Exploring RNNs and their ability to process sequential data.

### 11. Long Short-Term Memory (LSTM)
- Understanding LSTM networks and their role in handling long-term dependencies.

### 12. Transfer Learning
- Leveraging pre-trained models for transfer learning in neural networks.

## Conclusion

This section provides a summary of the topics learned throughout the labs.

## References

A list of references used in the tutorials can be found here.

## Additional Resources

- [Miniconda Documentation](https://docs.conda.io/en/latest/miniconda.html): Official documentation for Miniconda.
- [PyTorch Documentation](https://pytorch.org/docs/stable/index.html): Official documentation for PyTorch.
- [Deep Learning with PyTorch: A 60 Minute Blitz](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html): A beginner-friendly tutorial on deep learning with PyTorch.
- [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/): Online book by Michael Nielsen covering neural networks and deep learning concepts.

## Projects to implement (Optional)

<details>
<summary>Project 1: Image Classification</summary>

- Description: Build a neural network model that can classify images into different categories, such as cats and dogs.
- Steps:
    1. Collect a dataset of labeled images.
    2. Preprocess the images by resizing and normalizing them.
    3. Design and train a convolutional neural network (CNN) model using PyTorch.
    4. Evaluate the model's performance on a test set.
    5. Fine-tune the model to improve its accuracy.
    6. Test the model on new, unseen images.

</details>

<details>
<summary>Project 2: Sentiment Analysis</summary>

- Description: Develop a neural network model that can analyze the sentiment of text data, classifying it as positive, negative, or neutral.
- Steps:
    1. Gather a dataset of labeled text data with corresponding sentiment labels.
    2. Preprocess the text data by tokenizing, removing stopwords, and converting it into numerical representations.
    3. Build and train a recurrent neural network (RNN) model using PyTorch.
    4. Evaluate the model's performance on a validation set.
    5. Fine-tune the model by adjusting hyperparameters and architecture.
    6. Test the model on new, unseen text data.

</details>

<details>
<summary>Project 3: Stock Price Prediction</summary>

- Description: Create a neural network model that can predict future stock prices based on historical price data.
- Steps:
    1. Collect a dataset of historical stock prices, including features such as opening price, closing price, volume, etc.
    2. Preprocess the data by normalizing and splitting it into training and testing sets.
    3. Design and train a recurrent neural network (RNN) or long short-term memory (LSTM) model using PyTorch.
    4. Evaluate the model's performance by comparing predicted prices with actual prices.
    5. Fine-tune the model by adjusting hyperparameters and architecture.
    6. Use the model to make predictions on future stock price data.

</details>